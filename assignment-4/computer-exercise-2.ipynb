{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import computer_vision as cv\n",
    "from icecream import ic\n",
    "from tqdm import trange\n",
    "from numba import njit\n",
    "\n",
    "%load_ext snakeviz\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvlfeat\n",
      "  Using cached pyvlfeat-0.1.1a3.tar.gz (159 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pyvlfeat\n",
      "  Building wheel for pyvlfeat (setup.py): started\n",
      "  Building wheel for pyvlfeat (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyvlfeat\n",
      "Failed to build pyvlfeat\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pyvlfeat\n",
      "ERROR: Could not build wheels for pyvlfeat, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "%pip install pyvlfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cyvlfeat import sift \n",
    "# frames,desc=sift.sift(img,compute_descriptor=True,n_levels=1)\n",
    "# ip=(frames.T)[0:2,:]\n",
    "# desc=desc.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install cyvlfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift_points(img1, img2, marg):\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    # # img1 = cv2.medianBlur(img1, ksize = 5)\n",
    "    # img1 = cv2.normalize(img1, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # # img1 = img1.astype(np.float32)\n",
    "\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    # # img2 = cv2.medianBlur(img2, ksize = 5)\n",
    "    # img2 = cv2.normalize(img2, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # # img2 = img2.astype(np.float32)\n",
    "\n",
    "\n",
    "    # sift = cv2.SIFT_create(int nfeatures=0, int nOctaveLayers=3, double contrastThreshold=0.04, double edgeThreshold=10, double sigma=1.6)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # # orb = cv2.ORB_create()\n",
    "    # # kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    # # kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    # FLANN_INDEX_KDTREE = 1\n",
    "    # index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    # search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "    # flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    print('Number of matches:', np.size(matches,0))\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < marg*n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    draw_params = dict(matchColor=(255,0,255), singlePointColor=(0,255,0), matchesMask=None, flags=cv2.DrawMatchesFlags_DEFAULT)\n",
    "    img_match = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, **draw_params)\n",
    "\n",
    "    x1 = np.stack([kp1[match[0].queryIdx].pt for match in good_matches],1)\n",
    "    x2 = np.stack([kp2[match[0].trainIdx].pt for match in good_matches],1)\n",
    "\n",
    "    x1 = cv.homogenize(x1, multi=True)\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "\n",
    "    print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "    return x1, x2, img_match\n",
    "\n",
    "def get_sift_plot_points(img1_pts, img2_pts, img1):\n",
    "    x = [img1_pts[0,:], np.size(img1,1)+img2_pts[0,:]]\n",
    "    y = [img1_pts[1,:], img2_pts[1,:]]\n",
    "    return x, y\n",
    "\n",
    "def plot_sift_points(x1, x2, img1, img_match, path, save=False):\n",
    "    x, y = get_sift_plot_points(x1, x2, img1)\n",
    "\n",
    "    fig = plt.figure(figsize=(18,9))\n",
    "    ax = plt.axes()\n",
    "\n",
    "    ax.plot(x, y, 'o-', ms=5, lw=1, color='magenta')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.legend(loc=\"upper right\")\n",
    "    ax.imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import match_descriptors, plot_matches, SIFT\n",
    "\n",
    "def compute_sift_points_sk(img1, img2, marg):\n",
    "\n",
    "    # img1 = rgb2gray(img1)\n",
    "    # img2 = rgb2gray(img2)\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    descriptor_extractor = SIFT()\n",
    "\n",
    "    descriptor_extractor.detect_and_extract(img1)\n",
    "    keypoints1 = descriptor_extractor.keypoints\n",
    "    descriptors1 = descriptor_extractor.descriptors\n",
    "\n",
    "    descriptor_extractor.detect_and_extract(img2)\n",
    "    keypoints2 = descriptor_extractor.keypoints\n",
    "    descriptors2 = descriptor_extractor.descriptors\n",
    "\n",
    "    good_matches = match_descriptors(descriptors1, descriptors2, max_ratio=marg, cross_check=True)\n",
    "    fig, ax = plt.axes()\n",
    "    print('Number of matches:', np.size(good_matches,0))\n",
    "\n",
    "    # plt.gray()\n",
    "\n",
    "    # plot_matches(ax, img1, img2, keypoints1, keypoints2, good_matches)\n",
    "    \n",
    "    x1 = np.stack([keypoints1[match[0]].pt for match in good_matches],1)\n",
    "    x2 = np.stack([keypoints2[match[1]].pt for match in good_matches],1)\n",
    "\n",
    "    print(x1.shape, x2.shape)\n",
    "\n",
    "    x1 = cv.homogenize(x1, multi=True)\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "    print(x1.shape, x2.shape)\n",
    "    print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ransac_iterations(alpha, epsilon, s):\n",
    "    T = np.ceil(np.log(1-alpha) / np.log(1-epsilon**s))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_E_robust(K, x1_norm, x2_norm, n_its, n_samples, err_threshold_px):\n",
    "    \n",
    "    err_threshold = err_threshold_px / K[0,0]\n",
    "    best_inliers = None\n",
    "    best_E = None\n",
    "    max_inliers = 0\n",
    "\n",
    "    for t in trange(n_its):\n",
    "\n",
    "        rand_mask = np.random.choice(np.size(x1_norm,1), n_samples, replace=False)\n",
    "        E = cv.estimate_E_DLT(x1_norm[:,rand_mask], x2_norm[:,rand_mask], enforce=True, verbose=False)\n",
    "\n",
    "        D1, D2 = cv.compute_epipolar_errors(E, x1_norm, x2_norm)\n",
    "        inliers = ((D1**2 + D2**2) / 2) < err_threshold**2\n",
    "\n",
    "        n_inliers = np.sum(inliers)\n",
    "\n",
    "        if n_inliers > max_inliers:\n",
    "            best_inliers = np.copy(inliers)\n",
    "            best_E = np.copy(E)\n",
    "            max_inliers = n_inliers\n",
    "\n",
    "            print(np.sum(inliers), end='\\r')\n",
    "        \n",
    "    return best_E, best_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cameras_and_3D_points(X, C_arr, axis_arr, s, path, save=False):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    ax.plot(X[0], X[1], X[2], '.', ms=2, color='magenta', label='3D points')\n",
    "    cv.plot_cameras_and_axes(ax, C_arr, axis_arr, s)\n",
    "\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlabel('$z$')\n",
    "    ax.axis('equal')\n",
    "    ax.view_init(elev=-50, azim=-104, roll=45)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save:\n",
    "        fig.savefig(path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\erikn\\skola\\EEN020-Computer-Vision\\assignment-4'\n",
    "data = r'\\data-2023\\data'\n",
    "compex = r'\\compEx2data.mat'\n",
    "img1 = r'\\fountain1.png'\n",
    "img2 = r'\\fountain2.png'\n",
    "# img1 = r'\\round_church1.jpg'\n",
    "# img2 = r'\\round_church2.jpg'\n",
    "report = r'\\report-images'\n",
    "fountain1 = cv.load_image(path+data+img1)\n",
    "fountain2 = cv.load_image(path+data+img2)\n",
    "K = cv.convert_mat_to_np(path+data+compex, 'K')\n",
    "K_inv = np.linalg.inv(K)\n",
    "\n",
    "ransac = True\n",
    "plt_3D = True\n",
    "save = False\n",
    "snakeviz = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 4381\n",
      "Number of good matches: 353\n"
     ]
    }
   ],
   "source": [
    "ind = 3\n",
    "marg = 0.8\n",
    "x1, x2, fountain_match = compute_sift_points(fountain1, fountain2, marg)\n",
    "# plot_sift_points(x1, x2, fountain1, fountain_match, path+report+'/CE2_sift_{}.png'.format(ind), save=True)\n",
    "\n",
    "x1_norm = cv.transform_and_dehomogenize(K_inv, x1)\n",
    "x2_norm = cv.transform_and_dehomogenize(K_inv, x2)\n",
    "\n",
    "np.save(path+data+'/CE2_x1_norm_{}.npy'.format(ind), x1_norm)\n",
    "np.save(path+data+'/CE2_x2_norm_{}.npy'.format(ind), x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1_norm = cv.transform_and_dehomogenize(K_inv, x1)\n",
    "x2_norm = cv.transform_and_dehomogenize(K_inv, x2)\n",
    "\n",
    "# ind = 4\n",
    "# marg = 0.7\n",
    "# x1, x2 = compute_sift_points_sk(fountain1, fountain2, marg)\n",
    "\n",
    "# x1_norm = cv.transform_and_dehomogenize(K_inv, x1)\n",
    "# x2_norm = cv.transform_and_dehomogenize(K_inv, x2)\n",
    "\n",
    "# np.save(path+data+'/CE2_x1_norm_{}.npy'.format(ind), x1_norm)\n",
    "# np.save(path+data+'/CE2_x2_norm_{}.npy'.format(ind), x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "x1 = cv.homogenize(cv.convert_mat_to_np(path+data+'/CE2_sift_matlab.mat', 'xA'), multi=True)\n",
    "x2 = cv.homogenize(cv.convert_mat_to_np(path+data+'/CE2_sift_matlab.mat', 'xB'), multi=True)\n",
    "\n",
    "x1_norm = cv.transform_and_dehomogenize(K_inv, x1)\n",
    "x2_norm = cv.transform_and_dehomogenize(K_inv, x2)\n",
    "\n",
    "np.save(path+data+'/CE2_x1_norm_{}.npy'.format(ind), x1_norm)\n",
    "np.save(path+data+'/CE2_x2_norm_{}.npy'.format(ind), x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 93/100000 [00:00<02:00, 827.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 669/100000 [00:00<01:27, 1139.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2039/100000 [00:02<01:35, 1029.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12320/100000 [00:14<01:50, 795.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52174/100000 [00:51<00:37, 1261.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:53<00:00, 881.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. inliers: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ind = 3\n",
    "x1_norm = np.load(path+data+'/CE2_x1_norm_{}.npy'.format(ind))\n",
    "x2_norm = np.load(path+data+'/CE2_x2_norm_{}.npy'.format(ind))\n",
    "\n",
    "if False:\n",
    "    x = cv.convert_mat_to_np(path+data+'/compEx3data.mat', 'x')\n",
    "    x1 = cv.dehomogenize(x[0,0])\n",
    "    x2 = cv.dehomogenize(x[0,1])\n",
    "    x1_norm = cv.dehomogenize(np.linalg.inv(K) @ x1)\n",
    "    x2_norm = cv.dehomogenize(np.linalg.inv(K) @ x2)\n",
    "\n",
    "if ransac:\n",
    "    n_its = 100000\n",
    "    n_samples = 8\n",
    "    err_threshold_px = 4\n",
    "    E, inliers = estimate_E_robust(K, x1_norm, x2_norm, n_its, n_samples, err_threshold_px)\n",
    "\n",
    "    np.save(path+data+'/CE2_E_robust_{}.npy'.format(ind), E)\n",
    "    np.save(path+data+'/CE2_inliers_{}.npy'.format(ind), inliers)\n",
    "    print('No. inliers:', np.sum(inliers))\n",
    "    \n",
    "if snakeviz:\n",
    "    %snakeviz estimate_E_robust(K, x1_norm, x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E: [[ -0.04140149   6.0290843   -0.69372926]\n",
      " [  9.40405325   0.77104285  14.4009753 ]\n",
      " [ -0.44186359 -16.08240252   1.        ]]\n",
      "F: [[-1.00207849e-09  1.45680418e-07 -1.91482995e-04]\n",
      " [ 2.27229599e-07  1.85991205e-08  5.95944531e-04]\n",
      " [-2.56765358e-04 -1.31258941e-03  1.00000000e+00]]\n",
      "[1.72204901e+01 1.72204901e+01 1.36453547e-16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. valid coords for each camera pair: [   0 3680 1840 1840]\n",
      "Argmax(P2_arr): 1\n",
      "[[-0.          0.83732562]\n",
      " [-0.         -0.05681539]\n",
      " [-0.         -0.54374426]\n",
      " [ 1.          1.        ]] [[0.         0.80569901]\n",
      " [0.         0.01468276]\n",
      " [1.         0.59214316]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "ind = 2\n",
    "E = np.load(path+data+'/CE2_E_robust_{}.npy'.format(ind))\n",
    "inliers = np.load(path+data+'/CE2_inliers_{}.npy'.format(ind))\n",
    "x1_norm = np.load(path+data+'/CE2_x1_norm_{}.npy'.format(ind))\n",
    "x2_norm = np.load(path+data+'/CE2_x2_norm_{}.npy'.format(ind))\n",
    "\n",
    "x1_norm = x1_norm[:,inliers]\n",
    "x2_norm = x2_norm[:,inliers]\n",
    "\n",
    "F = cv.convert_E_to_F(E, K, K)\n",
    "\n",
    "print('\\nE:', E)\n",
    "print('F:', F)\n",
    "\n",
    "P2_arr = cv.extract_P_from_E(E)\n",
    "P1 = cv.get_canonical_camera()\n",
    "\n",
    "X_arr_dh = np.array([cv.dehomogenize(cv.triangulate_3D_point_DLT(P1, P2, x1_norm, x2_norm, print_svd=False)) for P2 in P2_arr])\n",
    "P2_valid, X_valid = cv.extract_valid_camera_and_points(P1, P2_arr, X_arr_dh)\n",
    "np.save(path+data+'/CE2_X_valid_{}.npy'.format(ind), X_valid)\n",
    "np.save(path+data+'/CE2_P2_valid_{}.npy'.format(ind), P2_valid)\n",
    "\n",
    "i = 0\n",
    "X_valid = X_arr_dh[i]\n",
    "P2_valid = P2_arr[i]\n",
    "\n",
    "if plt_3D:\n",
    "    P_arr = np.array([P1, P2_valid])\n",
    "    C_arr, axis_arr = cv.compute_camera_and_normalized_principal_axis(P_arr, multi=True)\n",
    "    s = 1\n",
    "    plot_cameras_and_3D_points(X_valid, C_arr, axis_arr, s, path+report+'/CE2_3D_P2_{}_{}.png'.format(i+1, ind), save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chalmers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
