{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n\\n\\n### Computing inliers between initial_pair and all other images ###\\n')\n",
    "\n",
    "# min_its = 10000\n",
    "# max_its = 60000\n",
    "# scale_its = 3\n",
    "# alpha = 0.99\n",
    "# compute_inliers = True\n",
    "\n",
    "# if compute_inliers:\n",
    "    \n",
    "#     for i in range(n_imgs):\n",
    "\n",
    "#         if i != init_pair[0]:\n",
    "#             print('\\nImage:', i+1, '/', n_imgs)\n",
    "\n",
    "#             x1_norm = x1s_norm_TR[i]\n",
    "#             x2_norm = x2s_norm_TR[i]\n",
    "#             E, inliers = estimate_E_robust(K, x1_norm, x2_norm, min_its, max_its, scale_its, alpha, pixel_threshold, essential_matrix=True, homography=True, verbose=True)\n",
    "\n",
    "#             np.save('data/dataset_{}_TR_E_{}.npy'.format(data_set, i), E)\n",
    "#             np.save('data/dataset_{}_TR_E_inliers_{}.npy'.format(data_set, i), inliers)\n",
    "\n",
    "#             if i == init_pair[1]:\n",
    "#                 # np.save('data/dataset_{}_TR_E_{}.npy'.format(data_set, init_pair[0]), E)\n",
    "#                 np.save('data/dataset_{}_TR_E_inliers_{}.npy'.format(data_set, init_pair[0]), inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1 = cv.get_canonical_camera()\n",
    "# best_P2 = None\n",
    "# best_X = None\n",
    "# max_inliers = 0\n",
    "# if epsilon > epsilon_E:\n",
    "\n",
    "#     # P2_arr = cv.extract_P_from_E(E)\n",
    "#     # X_arr = cv.compute_triangulated_X_from_extracted_P2_solutions(P1, P2_arr, x1_norm, x2_norm)\n",
    "#     # P2_valid, X_valid = cv.extract_valid_camera_and_points(P1, P2_arr, X_arr)\n",
    "#     # valid_inliers = compute_valid_inliers(P1, P2_valid, X_valid, inliers)\n",
    "#     # n_valid_inliers = np.sum(valid_inliers)\n",
    "#     # print(n_valid_inliers, n_inliers)\n",
    "\n",
    "#     # best_P2 = np.copy(P2_valid)\n",
    "#     # best_X = np.copy(X_valid)\n",
    "#     best_E = np.copy(E)\n",
    "#     best_inliers = np.copy(inliers)\n",
    "#     epsilon_E = epsilon\n",
    "#     print('No. inliers:', n_inliers, end='\\r')\n",
    "\n",
    "#     # if n_valid_inliers > max_inliers:\n",
    "#     #     best_inliers = np.copy(valid_inliers)\n",
    "#     #     best_P2 = np.copy(P2_valid)\n",
    "#     #     max_inliers = n_valid_inliers\n",
    "#     #     print('No. valid inliers:', n_valid_inliers, end='\\r')\n",
    "\n",
    "#         # epsilon = max_inliers / n_points\n",
    "#         # T = cv.compute_ransac_iterations(alpha, epsilon, n_samples)\n",
    "#         # print('New T:', T, 'New epsilon:', epsilon)\n",
    "#         # if t >= 4*T-1:\n",
    "#         #     print('Bailout at iteration:', t, T)\n",
    "#         #     break\n",
    "\n",
    "# valid_inliers = compute_valid_inliers(P1, best_P2, best_X, best_inliers)\n",
    "# n_valid_inliers = np.sum(valid_inliers)\n",
    "# print('No. valid inliers:', n_valid_inliers, 'No. inliers:', np.sum(best_inliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift_points_vlfeat(img1, img2, marg, verbose=False):\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) \n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # print('opencv:', des1.shape, des2.shape)\n",
    "\n",
    "    # kp1, des1 = vl.sift.sift(np.array(img1, dtype=np.float32), compute_descriptor=True)\n",
    "    # kp2, des2 = vl.sift.sift(np.array(img2, dtype=np.float32), compute_descriptor=True)\n",
    "\n",
    "    # print('vlfeat.', des1.shape, des2.shape)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < marg*n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    # x1 = np.column_stack([kp1[match[0].queryIdx,:2] for match in good_matches])\n",
    "    # x2 = np.column_stack([kp2[match[0].trainIdx,:2] for match in good_matches])\n",
    "    x1 = np.column_stack([kp1[match[0].queryIdx].pt for match in good_matches])\n",
    "    x2 = np.column_stack([kp2[match[0].trainIdx].pt for match in good_matches])\n",
    "    x1 = cv.homogenize(x1, multi=True)\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "\n",
    "    des1 = np.row_stack([des1[match[0].queryIdx] for match in good_matches])\n",
    "    des2 = np.row_stack([des2[match[0].trainIdx] for match in good_matches])\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of matches:', np.size(matches,0))\n",
    "        print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "    return x1, x2, kp1, kp2, des1, des2\n",
    "\n",
    "def compute_sift_points_TR_vlfeat(x1, des1, img2, marg, verbose=False):\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    # print('opencv:', des2.shape)\n",
    "\n",
    "    # kp2, des2 = vl.sift.sift(np.array(img2, dtype=np.float32), compute_descriptor=True)\n",
    "    # print('vlfeat.', des2.shape)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < marg*n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    x_idx = np.array([match[0].queryIdx for match in good_matches])\n",
    "    x1 = np.column_stack([x1[:,match[0].queryIdx] for match in good_matches])\n",
    "    # x2 = np.column_stack([kp2[match[0].trainIdx,:2] for match in good_matches])\n",
    "    x2 = np.column_stack([kp2[match[0].trainIdx].pt for match in good_matches])\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of matches:', np.size(matches,0))\n",
    "        print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "    return x1, x2, x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n### Computing and saving SIFT-points ###\\n')\n",
    "\n",
    "print('\\n\\n## For translation registration ##')\n",
    "\n",
    "sift_TR = False\n",
    "marg = 0.75\n",
    "\n",
    "if sift_TR:\n",
    "    \n",
    "    print(\"\\nImage:\", init_pair[1]+1, \"/\", n_imgs, '(initial image pair)')\n",
    "    x1_init, x2_init, kp1_init, kp2_init, des1_init, des2_init = compute_sift_points(img1_init, img2_init, marg, verbose=True)\n",
    "    np.save('data/dataset_{}_TR_x1_{}.npy'.format(data_set, init_pair[1]), x1_init)\n",
    "    np.save('data/dataset_{}_TR_x2_{}.npy'.format(data_set, init_pair[1]), x2_init)\n",
    "\n",
    "    X_visible = np.ones(x1_init.shape[1], dtype=bool)\n",
    "    np.save('data/dataset_{}_TR_X_visible_{}.npy'.format(data_set, init_pair[0]), X_visible)\n",
    "    np.save('data/dataset_{}_TR_X_visible_{}.npy'.format(data_set, init_pair[1]), X_visible)\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "\n",
    "        if i != init_pair[0] and i != init_pair[1]:\n",
    "\n",
    "            if i > int(n_imgs/2):\n",
    "                x1_init = np.copy(x2_init)\n",
    "                des1_init = np.copy(des2_init)\n",
    "            \n",
    "            print(\"\\nImage:\", i+1, \"/\", n_imgs)\n",
    "            img2 = imgs[i]\n",
    "            x1, x2, x_idx = compute_sift_points_TR(x1_init, des1_init, img2, marg, verbose=True)\n",
    "            x_idx = np.sort(x_idx)\n",
    "            X_visible = []\n",
    "            t = 0\n",
    "\n",
    "            for j in range(x1_init.shape[1]):\n",
    "                try:\n",
    "                    if j == x_idx[t]:\n",
    "                        X_visible.append(True)\n",
    "                        t += 1\n",
    "                    else:\n",
    "                        X_visible.append(False)\n",
    "                except:\n",
    "                    X_visible.append(False)\n",
    "            X_visible = np.array(X_visible)\n",
    "                    \n",
    "            np.save('data/dataset_{}_TR_X_visible_{}.npy'.format(data_set, i), X_visible)\n",
    "            np.save('data/dataset_{}_TR_x1_{}.npy'.format(data_set, i), x1)\n",
    "            np.save('data/dataset_{}_TR_x2_{}.npy'.format(data_set, i), x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n### Loading SIFT-points ###\\n')\n",
    "\n",
    "# SIFT points for rotation averaging\n",
    "x1s_norm_RA = []\n",
    "x2s_norm_RA = []\n",
    "matlab_RA = False\n",
    "\n",
    "if False:\n",
    "    for i in range(n_camera_pairs):\n",
    "\n",
    "        if matlab_RA:\n",
    "            x1 = cv.convert_mat_to_np('data/dataset_{}_RA_mat_x1_{}.mat'.format(data_set, i), 'x1')\n",
    "            x2 = cv.convert_mat_to_np('data/dataset_{}_RA_mat_x2_{}.mat'.format(data_set, i), 'x2')\n",
    "        else:\n",
    "            x1 = np.load('data/dataset_{}_RA_x1_{}.npy'.format(data_set, i))\n",
    "            x2 = np.load('data/dataset_{}_RA_x2_{}.npy'.format(data_set, i))\n",
    "\n",
    "        x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "        x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "        x1s_norm_RA.append(x1_norm)\n",
    "        x2s_norm_RA.append(x2_norm)\n",
    "        \n",
    "        \n",
    "    # SIFT points for translation registration\n",
    "    Xs_visible_TR = []\n",
    "    x1s_norm_TR = []\n",
    "    x2s_norm_TR = []\n",
    "    matlab_TR = False\n",
    "\n",
    "    for i in range(n_imgs):\n",
    "\n",
    "        if i != init_pair[0]:\n",
    "\n",
    "            if matlab_TR:\n",
    "                x1 = cv.convert_mat_to_np('data/dataset_{}_TR_mat_x1_{}.mat'.format(data_set, i), 'x1')\n",
    "                x2 = cv.convert_mat_to_np('data/dataset_{}_TR_mat_x2_{}.mat'.format(data_set, i), 'x2')\n",
    "            else:\n",
    "                x1 = np.load('data/dataset_{}_TR_x1_{}.npy'.format(data_set, i))\n",
    "                x2 = np.load('data/dataset_{}_TR_x2_{}.npy'.format(data_set, i))\n",
    "\n",
    "            x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "            x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "            x1s_norm_TR.append(x1_norm)\n",
    "            x2s_norm_TR.append(x2_norm)\n",
    "\n",
    "        elif i == init_pair[0]:\n",
    "            x1s_norm_TR.append(None)\n",
    "            x2s_norm_TR.append(None)\n",
    "\n",
    "        if matlab_TR:\n",
    "            X_visible = cv.convert_mat_to_np('data/dataset_{}_TR_mat_X_visible_{}.mat'.format(data_set, i), 'X_visible')[0]\n",
    "        else:\n",
    "            X_visible = np.load('data/dataset_{}_TR_X_visible_{}.npy'.format(data_set, i))\n",
    "            \n",
    "        Xs_visible_TR.append(np.array(X_visible, dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian_of_residual_wrt_w1(Pi, Xj):\n",
    "    \n",
    "    Ri = Pi[:,:-1]\n",
    "    S1 = cv.create_skew_symmetric_matrix(np.array([1,0,0]))\n",
    "\n",
    "    J1 = ((S1 @ Ri @ Xj[:-1]) * (Pi[0,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S1 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "    J2 = ((S1 @ Ri @ Xj[:-1]) * (Pi[1,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S1 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "\n",
    "    J = np.row_stack((J1, J2))   \n",
    "\n",
    "    return J\n",
    "\n",
    "def compute_jacobian_of_residual_wrt_w2(Pi, Xj):\n",
    "    \n",
    "    Ri = Pi[:,:-1]\n",
    "    S2 = cv.create_skew_symmetric_matrix(np.array([0,1,0]))\n",
    "\n",
    "    J1 = ((S2 @ Ri @ Xj[:-1]) * (Pi[0,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S2 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "    J2 = ((S2 @ Ri @ Xj[:-1]) * (Pi[1,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S2 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "\n",
    "    J = np.row_stack((J1, J2))   \n",
    "\n",
    "    return J\n",
    "\n",
    "def compute_jacobian_of_residual_wrt_w3(Pi, Xj):\n",
    "    \n",
    "    Ri = Pi[:,:-1]\n",
    "    S3 = cv.create_skew_symmetric_matrix(np.array([0,0,1]))\n",
    "\n",
    "    J1 = ((S3 @ Ri @ Xj[:-1]) * (Pi[0,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S3 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "    J2 = ((S3 @ Ri @ Xj[:-1]) * (Pi[1,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - ((S3 @ Ri @ Xj[:-1]) / (Pi[-1,:] @ Xj))\n",
    "\n",
    "    J = np.row_stack((J1, J2))   \n",
    "\n",
    "    return J\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def compute_jacobian_of_residual_wrt_X(Pi, Xj):\n",
    "    J1 = (Pi[-1,:] * (Pi[0,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - (Pi[0,:] / (Pi[-1,:] @ Xj))\n",
    "    J2 = (Pi[-1,:] * (Pi[1,:] @ Xj) / (Pi[-1,:] @ Xj)**2) - (Pi[1,:] / (Pi[-1,:] @ Xj))\n",
    "    J = np.row_stack((J1, J2))\n",
    "    return J\n",
    "\n",
    "\n",
    "\n",
    "def compute_axis_angle_representation(R):\n",
    "    \n",
    "    theta = np.arccos((np.trace(R)-1)/2)\n",
    "    a = (1/(2*np.sin(theta))) * np.array([R[2,1]-R[1,2], R[0,2]-R[2,0], R[1,0]-R[0,1]])\n",
    "    w = theta * a\n",
    "\n",
    "    return w\n",
    "\n",
    "def compute_R_matrix_exponential(w, approx=False):\n",
    "\n",
    "    wx = cv.create_skew_symmetric_matrix(w)\n",
    "    w_norm = LA.norm(w)\n",
    "    R = np.eye(3) + (np.sin(w_norm)*wx/w_norm) + ((1-np.cos(w_norm))*(wx @ wx)/(w_norm**2))\n",
    "    if approx:\n",
    "        R = np.eye(3) + wx\n",
    "\n",
    "    return R\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
