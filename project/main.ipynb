{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.io import loadmat\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import computer_vision as cv\n",
    "from icecream import ic\n",
    "from tqdm import trange\n",
    "import time\n",
    "from get_dataset_info import *\n",
    "\n",
    "# %load_ext snakeviz\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_E_robust(K, x1_norm, x2_norm, n_its, n_samples, err_threshold_px, alpha):\n",
    "    \n",
    "    err_threshold = err_threshold_px / K[0,0]\n",
    "    best_inliers = None\n",
    "    best_E = None\n",
    "    max_inliers = 0\n",
    "    epsilon = 0\n",
    "    T = n_its\n",
    "    n_points = x1_norm.shape[1]\n",
    "\n",
    "    for t in trange(n_its):\n",
    "\n",
    "        rand_mask = np.random.choice(np.size(x1_norm,1), n_samples, replace=False)\n",
    "        E = cv.estimate_E_DLT(x1_norm[:,rand_mask], x2_norm[:,rand_mask], enforce=True, verbose=False)\n",
    "\n",
    "        D1, D2 = cv.compute_epipolar_errors(E, x1_norm, x2_norm)\n",
    "        inliers = ((D1**2 + D2**2) / 2) < err_threshold**2\n",
    "\n",
    "        n_inliers = np.sum(inliers)\n",
    "\n",
    "        if n_inliers > max_inliers:\n",
    "            best_inliers = np.copy(inliers)\n",
    "            best_E = np.copy(E)\n",
    "            max_inliers = n_inliers\n",
    "            print(np.sum(inliers), end='\\r')\n",
    "\n",
    "            # epsilon = max_inliers / n_points\n",
    "            # T = cv.compute_ransac_iterations(alpha, epsilon, n_samples)\n",
    "            # print('New T:', T, 'New epsilon:', epsilon)\n",
    "            # if t >= 4*T-1:\n",
    "            #     print('Bailout at iteration:', t, T)\n",
    "            #     break\n",
    "        \n",
    "    return best_E, best_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 0\n",
    "K, img_names, init_pair, pixel_threshold = get_dataset_info(data_set)\n",
    "K_inv = LA.inv(K)\n",
    "imgs = cv.load_image(img_names, multi=True)\n",
    "n_imgs = imgs.shape[0]\n",
    "n_camera_pairs = n_imgs - 1\n",
    "img1_init = imgs[init_pair[0]]\n",
    "img2_init = imgs[init_pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Camera pair: 0 / 1\n",
      "Number of matches: 44542\n",
      "Number of good matches: 16518\n",
      "Number of matches: 44542\n",
      "Number of good matches: 16524\n"
     ]
    }
   ],
   "source": [
    "# Compute and save SIFT points\n",
    "marg = 0.7\n",
    "\n",
    "\n",
    "# SIFT points for relative orientation\n",
    "for i in range(n_camera_pairs):\n",
    "    print(\"\\nCamera pair:\", i+1, \"/\", n_camera_pairs)\n",
    "    img1 = imgs[i]\n",
    "    img2 = imgs[i+1]\n",
    "    x1, x2, _, _, _, _, _ = cv.compute_sift_points(img1, img2, marg)\n",
    "    np.save('data/RO_x1_{}_dataset_{}.npy'.format(i, data_set), x1)\n",
    "    np.save('data/RO_x2_{}_dataset_{}.npy'.format(i, data_set), x2)\n",
    "    \n",
    "\n",
    "# SIFT points for camera resectioning\n",
    "x1, x2, kp1, kp2, des1, des2, _ = cv.compute_sift_points(img1_init, img2_init, marg)\n",
    "np.save('data/CR_x1_{}_dataset_{}.npy'.format(init_pair[1], data_set), x1)\n",
    "np.save('data/CR_x2_{}_dataset_{}.npy'.format(init_pair[1], data_set), x2)\n",
    "\n",
    "for i in range(n_imgs):\n",
    "\n",
    "    if i != init_pair[0] and i != init_pair[1]:\n",
    "        \n",
    "        print(\"\\nImage:\", i+1, \"/\", n_imgs)\n",
    "        img2 = imgs[i]\n",
    "        x1, x2 = cv.compute_sift_points_sequential(kp1, des1, img2, marg)\n",
    "        np.save('data/CR_x1_{}_dataset_{}.npy'.format(i, data_set), x1)\n",
    "        np.save('data/CR_x2_{}_dataset_{}.npy'.format(i, data_set), x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SIFT points\n",
    "\n",
    "# SIFT points for relative orientation\n",
    "x1s_norm_RO = []\n",
    "x2s_norm_RO = []\n",
    "\n",
    "for i in range(n_camera_pairs):\n",
    "\n",
    "    x1 = np.load('data/RO_x1_{}_dataset_{}.npy'.format(i, data_set))\n",
    "    x2 = np.load('data/RO_x2_{}_dataset_{}.npy'.format(i, data_set))\n",
    "    x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "    x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "    x1s_norm_RO.append(x1_norm)\n",
    "    x2s_norm_RO.append(x2_norm)\n",
    "\n",
    "\n",
    "# SIFT points for camera resectioning\n",
    "x1s_norm_CR = []\n",
    "x2s_norm_CR = []\n",
    "\n",
    "for i in range(n_imgs):\n",
    "\n",
    "    if i != init_pair[0]:\n",
    "\n",
    "        x1 = np.load('data/CR_x1_{}_dataset_{}.npy'.format(i, data_set))\n",
    "        x2 = np.load('data/CR_x2_{}_dataset_{}.npy'.format(i, data_set))\n",
    "        x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "        x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "        x1s_norm_CR.append(x1_norm)\n",
    "        x2s_norm_CR.append(x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [00:00<00:05, 180.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1615\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 58/1000 [00:00<00:04, 190.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 271/1000 [00:01<00:04, 180.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 597/1000 [00:03<00:02, 187.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3473\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 176.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.62782246e+04 1.62782246e+04 3.44247125e-13]\n",
      "No. valid coords for each camera pair: [6946    0 3473 3473]\n",
      "Argmax(P2_arr): 0\n"
     ]
    }
   ],
   "source": [
    "# Compute absolute rotations\n",
    "\n",
    "n_its = 1000\n",
    "n_samples = 8\n",
    "alpha = 0.95\n",
    "P1 = cv.get_canonical_camera()\n",
    "abs_rots = [cv.get_camera_rotation(P1)]\n",
    "\n",
    "for i in range(n_camera_pairs):    \n",
    "    \n",
    "    x1_norm = x1s_norm_RO[i]\n",
    "    x2_norm = x2s_norm_RO[i]\n",
    "    E, inliers = estimate_E_robust(K, x1_norm, x2_norm, n_its, n_samples, pixel_threshold, alpha)\n",
    "    x1_norm_inliers = x1_norm[:,inliers]\n",
    "    x2_norm_inliers = x2_norm[:,inliers]\n",
    "\n",
    "    P2_arr = cv.extract_P_from_E(E)\n",
    "    X_arr = cv.get_triangulated_X_from_extracted_P2_solutions(P1, P2_arr, x1_norm_inliers, x2_norm_inliers)\n",
    "    P2, _ = cv.extract_valid_camera_and_points(P1, P2_arr, X_arr)\n",
    "    R2 = cv.get_camera_rotation(P2) @ abs_rots[i]\n",
    "    abs_rots.append(R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270761.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "epsilon = 0.2\n",
    "s = 8\n",
    "np.ceil(np.log(1-alpha) / np.log(1-epsilon**s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25c6cbab9d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_3D = True\n",
    "save = False\n",
    "\n",
    "x = np.linspace(0,10,11)\n",
    "y = np.random.rand(11)\n",
    "fig = plt.figure()\n",
    "plt.plot(x,y)\n",
    "fig.savefig('report-images/test.png', bbox_inches='tight')\n",
    "img = cv.load_image('report-images/test.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chalmers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
