{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import computer_vision as cv\n",
    "from tqdm import trange\n",
    "import time\n",
    "from get_dataset_info import *\n",
    "from scipy.spatial.transform import Rotation\n",
    "# import cyvlfeat as vl\n",
    "\n",
    "# %load_ext snakeviz\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D_points(X):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot(X[0], X[1], X[2], '.', ms=1, color='magenta', label='X')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlabel('$z$')\n",
    "    # ax.set_box_aspect([1, 1, 1]) \n",
    "    ax.set_aspect('equal')\n",
    "    # ax.view_init(elev=-50, azim=-104, roll=20)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_E_validity(E):\n",
    "    rank = LA.matrix_rank(E)\n",
    "    valid = True if rank == 2 else False\n",
    "    return valid\n",
    "\n",
    "def compute_E_inliers(E, x1_norm, x2_norm, err_threshold):\n",
    "    \n",
    "    distance1_arr, distance2_arr = cv.compute_epipolar_errors(E, x1_norm, x2_norm)\n",
    "    inliers = ((distance1_arr**2 + distance2_arr**2) / 2) < err_threshold**2\n",
    "    n_inliers = np.sum(inliers)\n",
    "    epsilon_E = n_inliers / x1_norm.shape[1]\n",
    "\n",
    "    return epsilon_E, inliers\n",
    "\n",
    "def verbose_E_robust(t, T_E, T_H, epsilon_E, epsilon_H, inliers, method):\n",
    "    print('Iteration:', t, 'T_E:', T_E, 'T_H:', T_H, 'epsilon_E:', np.round(epsilon_E, 2), 'epsilon_H:', np.round(epsilon_H, 2), 'No. inliers:', np.sum(inliers), 'From:', method)\n",
    "\n",
    "def compute_valid_inliers(P1, P2, X, inliers):\n",
    "\n",
    "    x1_norm_valid = P1 @ X\n",
    "    x2_norm_valid = P2 @ X\n",
    "    valid_coords_P1 = x1_norm_valid[-1,:] > 0\n",
    "    valid_coords_P2 = x2_norm_valid[-1,:] > 0\n",
    "    valid_coords = valid_coords_P1 * valid_coords_P2\n",
    "    valid_inliers = inliers * valid_coords\n",
    "\n",
    "    return valid_inliers\n",
    "\n",
    "def estimate_E_robust(K, x1_norm, x2_norm, min_its, max_its, scale_its, alpha, err_threshold_px, essential_matrix=True, homography=True, verbose=False):\n",
    "    \n",
    "    err_threshold = err_threshold_px / K[0,0]\n",
    "    best_E = None\n",
    "    best_inliers = None\n",
    "    n_points = x1_norm.shape[1]\n",
    "    n_E_samples = 8\n",
    "    n_H_samples = 4\n",
    "    best_epsilon_E = 0\n",
    "    best_epsilon_H = 0\n",
    "    T_E = max_its\n",
    "    T_H = max_its\n",
    "\n",
    "    t = 0\n",
    "    while t < T_E and t < T_H:\n",
    "        t += 1\n",
    "\n",
    "        if essential_matrix:\n",
    "            rand_mask = np.random.choice(n_points, n_E_samples, replace=False)\n",
    "            E = cv.estimate_E_DLT(x1_norm[:,rand_mask], x2_norm[:,rand_mask], enforce=True, verbose=False)\n",
    "            E_valid = compute_E_validity(E)\n",
    "\n",
    "            if E_valid:\n",
    "                epsilon_E, inliers = compute_E_inliers(E, x1_norm, x2_norm, err_threshold)\n",
    "                    \n",
    "                if epsilon_E > best_epsilon_E:\n",
    "                    best_E = np.copy(E)\n",
    "                    best_inliers = np.copy(inliers)\n",
    "                    best_epsilon_E = epsilon_E\n",
    "                    T_E = cv.compute_ransac_iterations(alpha, best_epsilon_E, n_E_samples, min_its, max_its, scale_its)\n",
    "\n",
    "                    if verbose:\n",
    "                        verbose_E_robust(t, T_E, T_H, best_epsilon_E, best_epsilon_H, best_inliers, method='E 8-point alg.')\n",
    "        \n",
    "        if homography:\n",
    "            rand_mask = np.random.choice(n_points, n_H_samples, replace=False)\n",
    "            H = cv.estimate_H_DLT(x1_norm[:,rand_mask], x2_norm[:,rand_mask], verbose=False)\n",
    "            x2_norm_proj = cv.dehomogenize(H @ x1_norm)\n",
    "            distance_arr = cv.compute_point_point_distance(x2_norm_proj, x2_norm)\n",
    "            inliers = distance_arr < err_threshold\n",
    "            n_inliers = np.sum(inliers)\n",
    "            epsilon_H = n_inliers / n_points\n",
    "\n",
    "            if epsilon_H > best_epsilon_H:\n",
    "                \n",
    "                # num, Rs, Ts, Ns = cv2.decomposeHomographyMat(H, np.eye(3))\n",
    "                R1, T1, R2, T2 = cv.homography_to_RT(H, x1_norm, x2_norm)\n",
    "                E1 = cv.compute_E_from_R_and_T(R1, T1)\n",
    "                E2 = cv.compute_E_from_R_and_T(R2, T2)\n",
    "\n",
    "                E1_valid = compute_E_validity(E1)\n",
    "                E2_valid = compute_E_validity(E2)\n",
    "\n",
    "                if E1_valid:\n",
    "                    epsilon_E, inliers = compute_E_inliers(E1, x1_norm, x2_norm, err_threshold)\n",
    "                        \n",
    "                    if epsilon_E > best_epsilon_E:\n",
    "                        best_E = np.copy(E1)\n",
    "                        best_inliers = np.copy(inliers)\n",
    "                        best_epsilon_E = epsilon_E\n",
    "                        best_epsilon_H = epsilon_H\n",
    "                        T_E = cv.compute_ransac_iterations(alpha, best_epsilon_E, n_E_samples, min_its, max_its, scale_its)\n",
    "                        T_H = cv.compute_ransac_iterations(alpha, best_epsilon_H, n_H_samples, min_its, max_its, scale_its)\n",
    "\n",
    "                        if verbose:\n",
    "                            verbose_E_robust(t, T_E, T_H, best_epsilon_E, best_epsilon_H, best_inliers, method='H 4-point alg.')\n",
    "\n",
    "                if E2_valid:\n",
    "                    epsilon_E, inliers = compute_E_inliers(E2, x1_norm, x2_norm, err_threshold)\n",
    "                        \n",
    "                    if epsilon_E > best_epsilon_E:\n",
    "                        best_E = np.copy(E2)\n",
    "                        best_inliers = np.copy(inliers)\n",
    "                        best_epsilon_E = epsilon_E\n",
    "                        best_epsilon_H = epsilon_H\n",
    "                        T_E = cv.compute_ransac_iterations(alpha, best_epsilon_E, n_E_samples, min_its, max_its, scale_its)\n",
    "                        T_H = cv.compute_ransac_iterations(alpha, best_epsilon_H, n_H_samples, min_its, max_its, scale_its)\n",
    "                        \n",
    "                        if verbose:\n",
    "                            verbose_E_robust(t, T_E, T_H, best_epsilon_E, best_epsilon_H, best_inliers, method='H 4-point alg.')\n",
    "        \n",
    "    print('Bailout at iteration:', t)\n",
    "    return best_E, best_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift_points(img1, img2, marg, flann=False, verbose=False):\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    if flann:\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < marg*n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    x1 = np.stack([kp1[match[0].queryIdx].pt for match in good_matches],1)\n",
    "    x2 = np.stack([kp2[match[0].trainIdx].pt for match in good_matches],1)\n",
    "    x1 = cv.homogenize(x1, multi=True)\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "\n",
    "    des1 = np.stack([des1[match[0].queryIdx] for match in good_matches],0)\n",
    "    des2 = np.stack([des2[match[0].trainIdx] for match in good_matches],0)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of matches:', np.size(matches,0))\n",
    "        print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "    return x1, x2, des1, des2\n",
    "\n",
    "def compute_sift_points_TR(x1, des1, img2, marg, flann=False, verbose=False):\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    if flann:\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < marg*n.distance:\n",
    "            good_matches.append([m])\n",
    "\n",
    "    x_idx = np.array([match[0].queryIdx for match in good_matches])\n",
    "    x1 = np.stack([x1[:,match[0].queryIdx] for match in good_matches],1)\n",
    "    x2 = np.stack([kp2[match[0].trainIdx].pt for match in good_matches],1)\n",
    "    x2 = cv.homogenize(x2, multi=True)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of matches:', np.size(matches,0))\n",
    "        print('Number of good matches:', np.size(x1,1))\n",
    "\n",
    "    return x1, x2, x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 2\n",
    "K, img_names, init_pair, pixel_threshold = get_dataset_info(data_set)\n",
    "# pixel_threshold *= 1\n",
    "K_inv = LA.inv(K)\n",
    "imgs = cv.load_image(img_names, multi=True)\n",
    "n_imgs = imgs.shape[0]\n",
    "n_camera_pairs = n_imgs - 1\n",
    "img1_init = imgs[init_pair[0]]\n",
    "img2_init = imgs[init_pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cameras_and_3D_points(X, C_arr, axis_arr, s, path, save=False):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    ax.plot(X[0], X[1], X[2], '.', ms=0.5, color='magenta', label='3D points')\n",
    "    cv.plot_cameras_and_axes(ax, C_arr, axis_arr, s)\n",
    "\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlabel('$z$')\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.view_init(elev=-50, azim=-104, roll=45)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save:\n",
    "        fig.savefig(path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feasible_points(P1, P2, X, percentile):\n",
    "    \n",
    "    x1 = P1 @ X\n",
    "    x2 = P2 @ X\n",
    "    x1_filter = x1[-1,:] > 0\n",
    "    x2_filter = x2[-1,:] > 0\n",
    "\n",
    "    X_bar = np.mean(X, axis=1)\n",
    "    X_norm = LA.norm(X - X_bar[:,None], axis=0)\n",
    "    norm_percentile = np.percentile(X_norm, percentile)\n",
    "    outlier_filter = X_norm < norm_percentile\n",
    "\n",
    "    feasible_pts = x1_filter * x2_filter * outlier_filter\n",
    "    return feasible_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_absolute_rotations(rel_rots, origin_idx, verbose=False):\n",
    "    \n",
    "    abs_rots = [rel_rots[0]]\n",
    "    for i in range(len(rel_rots)-1):\n",
    "\n",
    "        Ri = abs_rots[i]\n",
    "        R2 = rel_rots[i+1]\n",
    "        if LA.det(R2) < 0:\n",
    "            print('WARNING: det(R{}) < 0, not a rotation!'.format(i), LA.det(R2))\n",
    "            R2 = -R2\n",
    "        U, _, VT = LA.svd(R2, full_matrices=False)\n",
    "        R2 = U @ VT\n",
    "        Rj = R2 @ Ri\n",
    "        abs_rots.append(Rj)\n",
    "    \n",
    "    R0 = abs_rots[origin_idx]    \n",
    "    for i in range(len(abs_rots)):\n",
    "\n",
    "        Ri = abs_rots[i]\n",
    "        Ri = LA.inv(R0) @ Ri\n",
    "        abs_rots[i] = Ri\n",
    "\n",
    "        if verbose:\n",
    "            print('det(R{}):'.format(i), LA.det(Ri))\n",
    "        \n",
    "    return np.array(abs_rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rots_trans_RA(rel_cameras):\n",
    "\n",
    "    P1 = rel_cameras[0]\n",
    "    rots = [P1[:,:-1]]\n",
    "    trans = [P1[:,-1]]\n",
    "\n",
    "    for i in range(rel_cameras.shape[0]-1):\n",
    "        P2 = rel_cameras[i+1]\n",
    "        P2 /= P2[-1,2]\n",
    "        R2 = P2[:,:-1]\n",
    "        T2 = P2[:,-1]\n",
    "\n",
    "        Ri = rots[i]\n",
    "        Ti = trans[i]\n",
    "\n",
    "        Rj = R2 @ Ri\n",
    "        Tj = T2 + (Rj @ Ri.T @ Ti)\n",
    "\n",
    "        rots.append(Rj)\n",
    "        trans.append(Tj)\n",
    "\n",
    "    rots = np.array(rots)\n",
    "    trans = np.array(trans)\n",
    "\n",
    "    return rots, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "### Computing rotation averaging ###\n",
      "\n",
      "\n",
      "Camera pair: 1 / 11\n",
      "No. valid coords for each camera pair: [ 8236  8236 16472     0]\n",
      "Argmax(P2_arr): 2\n",
      "\n",
      "Camera pair: 2 / 11\n",
      "No. valid coords for each camera pair: [19770     0  9885  9885]\n",
      "Argmax(P2_arr): 0\n",
      "\n",
      "Camera pair: 3 / 11\n",
      "No. valid coords for each camera pair: [ 7192  7192     0 14384]\n",
      "Argmax(P2_arr): 3\n",
      "\n",
      "Camera pair: 4 / 11\n",
      "No. valid coords for each camera pair: [17416     0  8708  8708]\n",
      "Argmax(P2_arr): 0\n",
      "\n",
      "Camera pair: 5 / 11\n",
      "No. valid coords for each camera pair: [    0 23676 11838 11838]\n",
      "Argmax(P2_arr): 1\n",
      "\n",
      "Camera pair: 6 / 11\n",
      "No. valid coords for each camera pair: [15486     0  7743  7743]\n",
      "Argmax(P2_arr): 0\n",
      "\n",
      "Camera pair: 7 / 11\n",
      "No. valid coords for each camera pair: [ 9058  9058     0 18116]\n",
      "Argmax(P2_arr): 3\n",
      "\n",
      "Camera pair: 8 / 11\n",
      "No. valid coords for each camera pair: [    0 16392  8196  8196]\n",
      "Argmax(P2_arr): 1\n",
      "\n",
      "Camera pair: 9 / 11\n",
      "No. valid coords for each camera pair: [10685 10685 21370     0]\n",
      "Argmax(P2_arr): 2\n",
      "\n",
      "Camera pair: 10 / 11\n",
      "No. valid coords for each camera pair: [ 8316  8316 16632     0]\n",
      "Argmax(P2_arr): 2\n",
      "\n",
      "Camera pair: 11 / 11\n",
      "No. valid coords for each camera pair: [    2 14142  7072  7072]\n",
      "Argmax(P2_arr): 1\n",
      "det(R0): 0.9999999999999993\n",
      "det(R1): 0.9999999999999994\n",
      "det(R2): 0.9999999999999993\n",
      "det(R3): 0.9999999999999993\n",
      "det(R4): 0.9999999999999999\n",
      "det(R5): 0.9999999999999999\n",
      "det(R6): 0.9999999999999997\n",
      "det(R7): 0.9999999999999996\n",
      "det(R8): 0.9999999999999996\n",
      "det(R9): 0.9999999999999993\n",
      "det(R10): 0.9999999999999996\n",
      "det(R11): 0.9999999999999993\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n\\n### Computing rotation averaging ###\\n')\n",
    "\n",
    "marg = 0.75\n",
    "min_its = 0\n",
    "max_its = 50000\n",
    "scale_its = 4\n",
    "alpha = 0.99\n",
    "P1 = cv.get_canonical_camera()\n",
    "rel_cameras = [P1]\n",
    "\n",
    "sift = False\n",
    "ransac = False\n",
    "extract = True\n",
    "plot = False\n",
    "rot = True\n",
    "\n",
    "for i in range(n_camera_pairs):    \n",
    "    print('\\nCamera pair:', i+1, '/', n_camera_pairs)\n",
    "\n",
    "    if sift:\n",
    "        img1 = imgs[i]\n",
    "        img2 = imgs[i+1]\n",
    "        x1, x2, _, _ = compute_sift_points(img1, img2, marg, flann=True, verbose=True)\n",
    "        np.save('data/dataset_{}_RA_x1_{}.npy'.format(data_set, i), x1)\n",
    "        np.save('data/dataset_{}_RA_x2_{}.npy'.format(data_set, i), x2)   \n",
    "\n",
    "    x1 = np.load('data/dataset_{}_RA_x1_{}.npy'.format(data_set, i))\n",
    "    x2 = np.load('data/dataset_{}_RA_x2_{}.npy'.format(data_set, i))\n",
    "    x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "    x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "\n",
    "    if ransac:\n",
    "        E, inliers = estimate_E_robust(K, x1_norm, x2_norm, min_its, max_its, scale_its, alpha, pixel_threshold, essential_matrix=True, homography=True, verbose=True)\n",
    "        np.save('data/dataset_{}_RA_E_{}.npy'.format(data_set, i), E)\n",
    "        np.save('data/dataset_{}_RA_E_inliers_{}.npy'.format(data_set, i), inliers)\n",
    "\n",
    "    if extract:\n",
    "        E = np.load('data/dataset_{}_RA_E_{}.npy'.format(data_set, i))\n",
    "        inliers = np.load('data/dataset_{}_RA_E_inliers_{}.npy'.format(data_set, i))\n",
    "\n",
    "        x1_norm_inliers = x1_norm[:,inliers]\n",
    "        x2_norm_inliers = x2_norm[:,inliers]\n",
    "\n",
    "        P2_arr = cv.extract_P_from_E(E)\n",
    "        X_arr = cv.compute_triangulated_X_from_extracted_P2_solutions(P1, P2_arr, x1_norm_inliers, x2_norm_inliers)\n",
    "        P2, X = cv.extract_valid_camera_and_points(P1, P2_arr, X_arr, verbose=True)\n",
    "        rel_cameras.append(P2)\n",
    "\n",
    "        if plot:\n",
    "            percentile = 90\n",
    "            feasable_pts = compute_feasible_points(P1, P2, X, percentile)\n",
    "\n",
    "            P_arr = np.array([P1, P2])\n",
    "            C_arr, axis_arr = cv.compute_camera_center_and_normalized_principal_axis(P_arr, multi=True)\n",
    "            plot_cameras_and_3D_points(X[:,feasable_pts], C_arr, axis_arr, s=1, path=None, save=False)\n",
    "\n",
    "        # x1_norm_filter = x1_norm[:,feasable_pts]\n",
    "        # x2_norm_filter = x2_norm[:,feasable_pts]\n",
    "        # x1s_norm_RA[i] = x1_norm_filter\n",
    "        # x2s_norm_RA[i] = x2_norm_filter\n",
    "        # np.save('data/dataset_{}_RA_x1_{}.npy'.format(data_set, i), x1_norm_filter)\n",
    "        # np.save('data/dataset_{}_RA_x2_{}.npy'.format(data_set, i), x2_norm_filter)\n",
    "\n",
    "if rot:\n",
    "    rel_cameras = np.array(rel_cameras)\n",
    "    rel_rots = rel_cameras[:,:,:-1]\n",
    "    abs_rots = compute_absolute_rotations(rel_rots, init_pair[0], verbose=True)\n",
    "    rots_RA, trans_RA = compute_rots_trans_RA(rel_cameras)\n",
    "\n",
    "    np.save('data/dataset_{}_RA_abs_rots.npy'.format(data_set), abs_rots)\n",
    "    np.save('data/dataset_{}_RA_rots.npy'.format(data_set), rots_RA)\n",
    "    np.save('data/dataset_{}_RA_trans.npy'.format(data_set), trans_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "### Computing initial 3D-points ###\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. valid coords for each camera pair: [ 5613  5613     0 11226]\n",
      "Argmax(P2_arr): 3\n",
      "(3, 5051) (3, 5051) (5051, 128) (5051, 128) (4, 5051) (5051,)\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n\\n### Computing initial 3D-points ###\\n')\n",
    "\n",
    "min_its = 20000\n",
    "max_its = 30000\n",
    "scale_its = 3\n",
    "alpha = 0.99\n",
    "\n",
    "sift = False\n",
    "ransac = False\n",
    "extract = True\n",
    "\n",
    "if sift:\n",
    "    marg = 0.75\n",
    "    x1_init, x2_init, des1_init, des2_init = compute_sift_points(imgs[init_pair[0]], imgs[init_pair[1]], marg, flann=True, verbose=True)\n",
    "    np.save('data/dataset_{}_TR_x1_{}.npy'.format(data_set, init_pair[1]), x1_init)\n",
    "    np.save('data/dataset_{}_TR_x2_{}.npy'.format(data_set, init_pair[1]), x2_init)\n",
    "    np.save('data/dataset_{}_TR_des1_init.npy'.format(data_set), des1_init)\n",
    "    np.save('data/dataset_{}_TR_des2_init.npy'.format(data_set), des2_init)\n",
    "\n",
    "x1_init = np.load('data/dataset_{}_TR_x1_{}.npy'.format(data_set, init_pair[1]))\n",
    "x2_init = np.load('data/dataset_{}_TR_x2_{}.npy'.format(data_set, init_pair[1]))\n",
    "x1_init_norm = cv.dehomogenize(K_inv @ x1_init)\n",
    "x2_init_norm = cv.dehomogenize(K_inv @ x2_init)\n",
    "des1_init = np.load('data/dataset_{}_TR_des1_init.npy'.format(data_set))\n",
    "des2_init = np.load('data/dataset_{}_TR_des2_init.npy'.format(data_set))\n",
    "\n",
    "if ransac:\n",
    "    E, inliers = estimate_E_robust(K, x1_init_norm, x2_init_norm, min_its, max_its, scale_its, alpha, pixel_threshold, essential_matrix=True, homography=True, verbose=True)\n",
    "    np.save('data/dataset_{}_TR_E.npy'.format(data_set), E)\n",
    "    np.save('data/dataset_{}_TR_E_inliers.npy'.format(data_set), inliers)\n",
    "\n",
    "if extract:\n",
    "    E = np.load('data/dataset_{}_TR_E.npy'.format(data_set))\n",
    "    inliers = np.load('data/dataset_{}_TR_E_inliers.npy'.format(data_set))\n",
    "    x1_init_norm_inliers = x1_init_norm[:,inliers]\n",
    "    x2_init_norm_inliers = x2_init_norm[:,inliers]\n",
    "    des1_init_inliers = des1_init[inliers]\n",
    "    des2_init_inliers = des2_init[inliers]\n",
    "\n",
    "    P1 = cv.get_canonical_camera()\n",
    "    P2_arr = cv.extract_P_from_E(E)\n",
    "    X_arr = cv.compute_triangulated_X_from_extracted_P2_solutions(P1, P2_arr, x1_init_norm_inliers, x2_init_norm_inliers)\n",
    "    P2, X_init_inliers = cv.extract_valid_camera_and_points(P1, P2_arr, X_arr, verbose=True)\n",
    "\n",
    "    # P_arr = np.array([P1, P2])\n",
    "    # C_arr, axis_arr = cv.compute_camera_center_and_normalized_principal_axis(P_arr, multi=True)\n",
    "    # plot_cameras_and_3D_points(X_init[:,inliers], C_arr, axis_arr, s=1, path=None, save=False)\n",
    "\n",
    "    # R_init = rots[init_pair[0]]\n",
    "    # X_init = LA.inv(R_init) @ X_init[:-1,:]\n",
    "\n",
    "    percentile = 90\n",
    "    feasible_pts = compute_feasible_points(P1, P2, X_init_inliers, percentile)\n",
    "\n",
    "    x1_init_norm_feasible_inliers = x1_init_norm_inliers[:,feasible_pts]\n",
    "    x2_init_norm_feasible_inliers = x2_init_norm_inliers[:,feasible_pts]\n",
    "    des1_init_feasible_inliers = des1_init_inliers[feasible_pts]\n",
    "    des2_init_feasible_inliers = des2_init_inliers[feasible_pts]\n",
    "    X_init_feasible_inliers = X_init_inliers[:,feasible_pts]\n",
    "    \n",
    "    X_init_idx = np.ones(X_init_feasible_inliers.shape[1], dtype=bool)\n",
    "    np.save('data/dataset_{}_TR_x1_norm_{}.npy'.format(data_set, i), x1_init_norm_feasible_inliers)\n",
    "    np.save('data/dataset_{}_TR_x2_norm_{}.npy'.format(data_set, i), x2_init_norm_feasible_inliers)\n",
    "    np.save('data/dataset_{}_TR_X_idx_{}.npy'.format(data_set, init_pair[1]), X_init_idx)\n",
    "\n",
    "    print(x1_init_norm_feasible_inliers.shape, x2_init_norm_feasible_inliers.shape, des1_init_feasible_inliers.shape, des2_init_feasible_inliers.shape, X_init_feasible_inliers.shape, X_init_idx.shape)\n",
    "\n",
    "    plot_3D_points(X_init_feasible_inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_T_robust(K, R, X, x_norm, min_its, max_its, scale_its, alpha, err_threshold_px, DLT1=False, verbose=False):\n",
    "    \n",
    "    err_threshold = err_threshold_px / K[0,0]\n",
    "    best_T = None\n",
    "    best_inliers = None\n",
    "    best_epsilon = 0\n",
    "    n_points = x_norm.shape[1]\n",
    "    n_samples = 2\n",
    "    ransac_its = max_its\n",
    "\n",
    "    t = 0\n",
    "    while t < ransac_its:\n",
    "        t += 1\n",
    "\n",
    "        rand_mask = np.random.choice(n_points, n_samples, replace=False)\n",
    "        if DLT1:\n",
    "            T = cv.estimate_T_DLT_1(x_norm[:,rand_mask], verbose=False)\n",
    "        else:\n",
    "            T = cv.estimate_T_DLT_2(R, x_norm[:,rand_mask], verbose=False)\n",
    "\n",
    "        x_norm_proj = cv.dehomogenize(R @ X + T[:,np.newaxis])\n",
    "        distance_arr = cv.compute_point_point_distance(x_norm_proj, x_norm)\n",
    "        inliers = distance_arr < err_threshold\n",
    "        n_inliers = np.sum(inliers)\n",
    "        epsilon = n_inliers / n_points\n",
    "\n",
    "        if epsilon > best_epsilon:\n",
    "            best_T = np.copy(T)\n",
    "            best_inliers = np.copy(inliers)\n",
    "            best_epsilon = epsilon\n",
    "            ransac_its = cv.compute_ransac_iterations(alpha, best_epsilon, n_samples, min_its, max_its, scale_its)\n",
    "            if verbose:\n",
    "                print('Iteration:', t, 'T:', ransac_its, 'epsilon:', np.round(best_epsilon, 2), 'No. inliers:', np.sum(inliers))\n",
    "    \n",
    "    print('Bailout at iteration:', t)\n",
    "    return best_T, best_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "### Computing translation registrations ###\n",
      "\n",
      "\n",
      "Image: 1 / 12\n",
      "(3, 2515) (4, 2515)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1275 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 2 / 12\n",
      "(3, 2857) (4, 2857)\n",
      "Iteration: 597 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 3 / 12\n",
      "(3, 2975) (4, 2975)\n",
      "Iteration: 17 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 4 / 12\n",
      "(3, 3424) (4, 3424)\n",
      "Iteration: 3 T: 30000 epsilon: 0.0 No. inliers: 3\n",
      "Iteration: 170 T: 30000 epsilon: 0.01 No. inliers: 20\n",
      "Iteration: 219 T: 30000 epsilon: 0.01 No. inliers: 21\n",
      "Iteration: 289 T: 30000 epsilon: 0.01 No. inliers: 22\n",
      "Iteration: 380 T: 30000 epsilon: 0.01 No. inliers: 40\n",
      "Iteration: 404 T: 9858.0 epsilon: 0.02 No. inliers: 74\n",
      "Iteration: 1830 T: 7650.0 epsilon: 0.02 No. inliers: 84\n",
      "Bailout at iteration: 7650\n",
      "\n",
      "Image: 5 / 12\n",
      "\n",
      "Image: 6 / 12\n",
      "(3, 3724) (4, 3724)\n",
      "Iteration: 3 T: 30000 epsilon: 0.0 No. inliers: 7\n",
      "Iteration: 14 T: 30000 epsilon: 0.0 No. inliers: 10\n",
      "Iteration: 16 T: 30000 epsilon: 0.01 No. inliers: 27\n",
      "Iteration: 180 T: 30000 epsilon: 0.01 No. inliers: 42\n",
      "Iteration: 1278 T: 14225.0 epsilon: 0.02 No. inliers: 67\n",
      "Iteration: 3037 T: 9049.0 epsilon: 0.02 No. inliers: 84\n",
      "Bailout at iteration: 9049\n",
      "\n",
      "Image: 7 / 12\n",
      "(3, 3663) (4, 3663)\n",
      "Iteration: 90 T: 30000 epsilon: 0.0 No. inliers: 3\n",
      "Iteration: 133 T: 2781.0 epsilon: 0.04 No. inliers: 149\n",
      "Iteration: 448 T: 2268.0 epsilon: 0.05 No. inliers: 165\n",
      "Iteration: 817 T: 995.0 epsilon: 0.07 No. inliers: 249\n",
      "Bailout at iteration: 995\n",
      "\n",
      "Image: 8 / 12\n",
      "(3, 5051) (4, 5051)\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 9 / 12\n",
      "(3, 3298) (4, 3298)\n",
      "Iteration: 1776 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 10 / 12\n",
      "(3, 3057) (4, 3057)\n",
      "Iteration: 1059 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 11 / 12\n",
      "(3, 2830) (4, 2830)\n",
      "Iteration: 4467 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n",
      "\n",
      "Image: 12 / 12\n",
      "(3, 2481) (4, 2481)\n",
      "Iteration: 353 T: 30000 epsilon: 0.0 No. inliers: 1\n",
      "Bailout at iteration: 30000\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n\\n### Computing translation registrations ###\\n')\n",
    "\n",
    "marg = 0.75\n",
    "min_its = 0\n",
    "max_its = 30000\n",
    "scale_its = 1\n",
    "alpha = 0.99\n",
    "trans = []\n",
    "\n",
    "des_X = des1_init_feasible_inliers.copy()\n",
    "x_norm_feasible_inliers = x1_init_norm_feasible_inliers.copy()\n",
    "abs_rots = np.load('data/dataset_{}_RA_abs_rots.npy'.format(data_set))\n",
    "keep_rots = np.ones(abs_rots.shape[0], dtype=bool)\n",
    "\n",
    "sift = False\n",
    "plot = False\n",
    "ransac = True\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    print('\\nImage:', i+1, '/', n_imgs)\n",
    "\n",
    "    if i != init_pair[0]:\n",
    "\n",
    "        if sift and i != init_pair[1]:\n",
    "            img2 = imgs[i]\n",
    "            \n",
    "            # if i < int((init_pair[0]+init_pair[1])/2):\n",
    "            #     des_X = des1_init_feasible_inliers.copy()\n",
    "            #     x_norm_feasible_inliers = x1_init_norm_feasible_inliers.copy()\n",
    "            # else:\n",
    "            #     des_X = des2_init_feasible_inliers.copy()\n",
    "            #     x_norm_feasible_inliers = x2_init_norm_feasible_inliers.copy()\n",
    "            \n",
    "            x1_norm, x2, X_idx = compute_sift_points_TR(x_norm_feasible_inliers, des_X, img2, marg, flann=True, verbose=True)\n",
    "            x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "\n",
    "            np.save('data/dataset_{}_TR_x1_norm_{}.npy'.format(data_set, i), x1_norm)\n",
    "            np.save('data/dataset_{}_TR_x2_norm_{}.npy'.format(data_set, i), x2_norm)\n",
    "            np.save('data/dataset_{}_TR_X_idx_{}.npy'.format(data_set, i), X_idx)\n",
    "\n",
    "        x_norm = np.load('data/dataset_{}_TR_x2_norm_{}.npy'.format(data_set, i))\n",
    "        X_idx = np.load('data/dataset_{}_TR_X_idx_{}.npy'.format(data_set, i))\n",
    "        X = X_init_feasible_inliers[:,X_idx]        \n",
    "        R = abs_rots[i]\n",
    "        print(x_norm.shape, X.shape)\n",
    "\n",
    "        if plot:\n",
    "            plot_3D_points(X)\n",
    "\n",
    "        if ransac:\n",
    "            T, inliers = estimate_T_robust(K, R, X[:-1], x_norm, min_its, max_its, scale_its, alpha, 5*pixel_threshold, DLT1=False, verbose=True)\n",
    "            # T = cv.estimate_T_DLT_2(R, x_norm[:,inliers], verbose=False)            \n",
    "            np.save('data/dataset_{}_TR_T_inliers_{}.npy'.format(data_set, i), inliers)\n",
    "    else:\n",
    "        T = np.zeros(3)\n",
    "    \n",
    "    if ransac:\n",
    "        if T is not None:\n",
    "            trans.append(T)\n",
    "        else:\n",
    "            keep_rots[i] = False\n",
    "\n",
    "trans = np.array(trans)\n",
    "abs_rots = abs_rots[keep_rots]\n",
    "np.save('data/dataset_{}_TR_trans.npy'.format(data_set), trans)\n",
    "np.save('data/dataset_{}_TR_abs_rots.npy'.format(data_set), trans)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikn\\AppData\\Local\\Temp\\ipykernel_2892\\3795570632.py:3: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos((np.trace(R)-1)/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x0` is infeasible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m w \u001b[38;5;241m=\u001b[39m compute_axis_angle_representation(R)\n\u001b[0;32m     61\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((w, T, X[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mravel()))\n\u001b[1;32m---> 62\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleast_squares\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_residual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_norm_inliers_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCost:\u001b[39m\u001b[38;5;124m'\u001b[39m, result\u001b[38;5;241m.\u001b[39mcost)\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\venv_chalmers\\lib\\site-packages\\scipy\\optimize\\_lsq\\least_squares.py:820\u001b[0m, in \u001b[0;36mleast_squares\u001b[1;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach lower bound must be strictly less than each \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper bound.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_bounds(x0, lb, ub):\n\u001b[1;32m--> 820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`x0` is infeasible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    822\u001b[0m x_scale \u001b[38;5;241m=\u001b[39m check_x_scale(x_scale, x0)\n\u001b[0;32m    824\u001b[0m ftol, xtol, gtol \u001b[38;5;241m=\u001b[39m check_tolerance(ftol, xtol, gtol, method)\n",
      "\u001b[1;31mValueError\u001b[0m: `x0` is infeasible."
     ]
    }
   ],
   "source": [
    "def compute_axis_angle_representation(R):\n",
    "    \n",
    "    theta = np.arccos((np.trace(R)-1)/2)\n",
    "    a = (1/(2*np.sin(theta))) * np.array([R[2,1]-R[1,2], R[0,2]-R[2,0], R[1,0]-R[0,1]])\n",
    "    print(a)\n",
    "    w = theta * a\n",
    "\n",
    "    return w\n",
    "\n",
    "def compute_R_matrix_exponential(w, approx=False):\n",
    "\n",
    "    wx = cv.create_skew_symmetric_matrix(w)\n",
    "    w_norm = LA.norm(w)\n",
    "    R = np.eye(3) + (np.sin(w_norm)*wx/w_norm) + ((1-np.cos(w_norm))*(wx @ wx)/(w_norm**2))\n",
    "    if approx:\n",
    "        R = np.eye(3) + wx\n",
    "\n",
    "    return R\n",
    "\n",
    "def compute_residual(params, x, n_points):\n",
    "\n",
    "    w = params[0:3]\n",
    "    T = params[3:6]\n",
    "    X = params[6:].reshape(3, n_points)\n",
    "    print(X.shape)\n",
    "    \n",
    "    R = compute_R_matrix_exponential(w, approx=True)\n",
    "    U, _, VT = LA.svd(R, full_matrices=False)\n",
    "    R = U @ VT\n",
    "    x_proj = cv.dehomogenize(R @ X + T[:,None])\n",
    "    residual = x_proj - x\n",
    "\n",
    "    return residual.ravel()\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n\\n### Refining translation vectors ###\\n')\n",
    "\n",
    "for i in range(n_imgs):\n",
    "\n",
    "    if i != 0:\n",
    "\n",
    "        inliers = np.load('data/dataset_{}_TR_E_inliers_{}.npy'.format(data_set, i))\n",
    "\n",
    "        if i == init_pair[0]:\n",
    "            x_norm = x1s_norm_TR[init_pair[1]]\n",
    "        else:\n",
    "            x_norm = x2s_norm_TR[i]\n",
    "        x_norm_inliers = x_norm[:,inliers] \n",
    "\n",
    "        X_visible = Xs_visible_TR[i]\n",
    "        X_visible_inliers = X_init[:,X_visible][:,inliers]\n",
    "\n",
    "        X_norm = LA.norm(X_visible_inliers - X_bar[:,None], axis=0)\n",
    "        pts_filter = X_norm < norm_percentile\n",
    "        X_visible_inliers_filter = X_visible_inliers[:,pts_filter]\n",
    "        x_norm_inliers_filter = x_norm_inliers[:,pts_filter]\n",
    "\n",
    "        n_points = x_norm_inliers_filter.shape[1]\n",
    "        R = rots[i]\n",
    "        T = trans[i]\n",
    "\n",
    "        w = compute_axis_angle_representation(R)\n",
    "        x0 = np.hstack((w, T, X[:-1].ravel()))\n",
    "        result = scipy.optimize.least_squares(compute_residual, x0, method='lm', args=(x_norm_inliers_filter, n_points))\n",
    "        print(result.x, 'Cost:', result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "(11, 3)\n",
      "No. cameras: 11\n"
     ]
    }
   ],
   "source": [
    "cameras = []\n",
    "abs_rots = np.load('data/dataset_{}_TR_abs_rots.npy'.format(data_set))\n",
    "trans = np.load('data/dataset_{}_TR_trans.npy'.format(data_set))\n",
    "\n",
    "RA = False\n",
    "\n",
    "if RA:\n",
    "    abs_rots = np.load('data/dataset_{}_RA_rots.npy'.format(data_set))\n",
    "    trans = np.load('data/dataset_{}_RA_trans.npy'.format(data_set))\n",
    "\n",
    "for i in range(len(trans)):\n",
    "    try:\n",
    "        T = trans[i]\n",
    "        R = abs_rots[i]\n",
    "        cameras.append(np.column_stack((R, T)))\n",
    "        print(abs_rots.shape)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "cameras = np.array(cameras)\n",
    "print('No. cameras:', cameras.shape[0]) # fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     X_final \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m C_arr, axis_arr \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_camera_center_and_normalized_principal_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcameras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m plot_cameras_and_3D_points(X_final, C_arr, axis_arr, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\EEN020-Computer-Vision\\project\\computer_vision.py:63\u001b[0m, in \u001b[0;36mcompute_camera_center_and_normalized_principal_axis\u001b[1;34m(P, multi)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_camera_center_and_normalized_principal_axis\u001b[39m(P, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi:\n\u001b[1;32m---> 63\u001b[0m         C_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([homogenize(compute_camera_center(P[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39msize(P,\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m     64\u001b[0m         axis_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([homogenize(compute_normalized_principal_axis(P[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39msize(P,\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\EEN020-Computer-Vision\\project\\computer_vision.py:63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_camera_center_and_normalized_principal_axis\u001b[39m(P, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi:\n\u001b[1;32m---> 63\u001b[0m         C_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([homogenize(\u001b[43mcompute_camera_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39msize(P,\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m     64\u001b[0m         axis_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([homogenize(compute_normalized_principal_axis(P[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39msize(P,\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\EEN020-Computer-Vision\\project\\computer_vision.py:47\u001b[0m, in \u001b[0;36mcompute_camera_center\u001b[1;34m(P)\u001b[0m\n\u001b[0;32m     45\u001b[0m M \u001b[38;5;241m=\u001b[39m P[:,:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     46\u001b[0m P4 \u001b[38;5;241m=\u001b[39m P[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 47\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43mLA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m P4)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\venv_chalmers\\lib\\site-packages\\numpy\\linalg\\linalg.py:556\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    554\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[0;32m    555\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m--> 556\u001b[0m \u001b[43m_assert_stacked_square\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\erikn\\skola\\venv_chalmers\\lib\\site-packages\\numpy\\linalg\\linalg.py:213\u001b[0m, in \u001b[0;36m_assert_stacked_square\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    211\u001b[0m m, n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m!=\u001b[39m n:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast 2 dimensions of the array must be square\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "print('\\n\\n\\n### Triangulating final 3D-reconstruction ###\\n')\n",
    "\n",
    "X_final = []\n",
    "reconstruction = False\n",
    "\n",
    "if reconstruction:\n",
    "    for i in range(len(cameras)-1):\n",
    "        P1 = cameras[i]\n",
    "        P2 = cameras[i+1]\n",
    "\n",
    "        x1 = np.load('data/dataset_{}_RA_x1_{}.npy'.format(data_set, i))\n",
    "        x2 = np.load('data/dataset_{}_RA_x2_{}.npy'.format(data_set, i))\n",
    "        x1_norm = cv.dehomogenize(K_inv @ x1)\n",
    "        x2_norm = cv.dehomogenize(K_inv @ x2)\n",
    "        \n",
    "        inliers = np.load('data/dataset_{}_RA_E_inliers_{}.npy'.format(data_set, i))\n",
    "        x1_norm_inliers = x1_norm[:,inliers]\n",
    "        x2_norm_inliers = x2_norm[:,inliers]\n",
    "\n",
    "        percentile = 90\n",
    "        X_inliers = cv.triangulate_3D_point_DLT(P1, P2, x1_norm_inliers, x2_norm_inliers, verbose=False)\n",
    "        feasible_pts = compute_feasible_points(P1, P2, X_inliers, percentile)\n",
    "        X_final.append(X_inliers[:,feasible_pts])\n",
    "\n",
    "    X_final = np.column_stack(X_final)\n",
    "else:\n",
    "    X_final = [0,0,0]\n",
    "\n",
    "C_arr, axis_arr = cv.compute_camera_center_and_normalized_principal_axis(cameras, multi=True)\n",
    "plot_cameras_and_3D_points(X_final, C_arr, axis_arr, s=1, path=None, save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chalmers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
